{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Esha Sarkar\n",
    "Content: Discrimination Control Using Deep Neural Network\n",
    "'''\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "XTrain = mnist.train.images\n",
    "YTrain = mnist.train.labels\n",
    "XTest = mnist.test.images\n",
    "YTest = mnist.test.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images changed are 27500\n",
      "No. of images changed are 6000\n"
     ]
    }
   ],
   "source": [
    "#------------------Make a modified Dataset with a dot/flower inserted in random images across the training and test dataset\n",
    "def TransformMNIST (Percentage,OrigX,OrigY):\n",
    "\n",
    "    #Choose random images to insert sensitive information\n",
    "    SelectedImages = np.random.choice(int(OrigX.shape[0]),int((Percentage/100)*OrigX.shape[0]),replace=False) \n",
    "    print ('No. of images changed are', SelectedImages.shape[0]) #Choose random images to insert sensitive information\n",
    "\n",
    "    SubX = OrigX[SelectedImages]\n",
    "    SubX[:,729] = 1\n",
    "    \n",
    "    #Uncomment the following 4 lines if you want the flower as sensitive feature\n",
    "    SubX[:,700] = 1\n",
    "    SubX[:,702] = 1\n",
    "    SubX[:,756] = 1\n",
    "    SubX[:,758] = 1\n",
    "    \n",
    "    SubY = OrigY[SelectedImages]\n",
    "    SenYCol = np.zeros((OrigY.shape[0],2))\n",
    "    NewY = np.concatenate((OrigY,SenYCol),axis=1)\n",
    "\n",
    "    for num,i in enumerate(SelectedImages):\n",
    "        OrigX[i]=SubX[num]\n",
    "        NewY[i][11]=1\n",
    "    NewX = OrigX\n",
    "    for i in range(int(OrigX.shape[0])):\n",
    "        if i not in SelectedImages:\n",
    "            NewY[i][10]=1\n",
    "    return (SelectedImages, NewX,NewY)\n",
    "\n",
    "s,XTrainPrime, YTrainPrime = TransformMNIST(50,XTrain,YTrain)\n",
    "_,XTestPrime, YTestPrime = TransformMNIST(60,XTest,YTest)\n",
    "#These are our dataset for the rest of the project\n",
    "XTrain = mnist.train.images\n",
    "YTrain = mnist.train.labels\n",
    "XTest = mnist.test.images\n",
    "YTest = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How a transformed image looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCD8QFOEHgiL8QFCEHwjq/wHUMAkOC0fgHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26dfa33dd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=s[0]\n",
    "X=XTrainPrime[n]\n",
    "TempImage = X.reshape((28,28))\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training information:\n",
    "Each type of optimization followed will have three cell numbers as follows:\n",
    "    <br>Cell no. A: it defines the parameters\n",
    "    <br>Cell no. B: it performs the optimization\n",
    "    <br>Cell no. C: it shows how successful the encoder and classifier have been"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Optimization\n"
     ]
    }
   ],
   "source": [
    "#1A\n",
    "'''Simplest Architecture:\n",
    "    This just has one layer for encoder and one layer for classifier\n",
    "    There are no constraints on how good the generated images are and how well it is getting classified \n",
    "    Also, I am parallelizing the architecture for classifier\n",
    "'''\n",
    "\n",
    "alpha = (1/2)\n",
    "\n",
    "    \n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 12]) # 0-9 digits recognition => 1 class\n",
    "\n",
    "\n",
    "'''-----------------------------------------Encoder Training----------------------------------------------------'''\n",
    "W1 = tf.Variable(tf.random_uniform([784, 300],-1,1))\n",
    "b1 = tf.Variable(tf.random_uniform([300],-1,1))\n",
    "W2 = tf.Variable(tf.random_uniform([300, 784],-1,1))\n",
    "b2 = tf.Variable(tf.random_uniform([784],-1,1))\n",
    "\n",
    "Hidden1 = tf.nn.relu(tf.matmul(x, W1) + b1);\n",
    "EncImagesTemp = tf.nn.tanh(tf.matmul(Hidden1, W2) + b2);\n",
    "#These are the encodings of the images\n",
    "\n",
    "c = tf.reduce_max(EncImagesTemp)\n",
    "d = tf.reduce_min(EncImagesTemp)\n",
    "#The Encodings need to be scaled so that the final values are between 0 and 1 (like original MNIST)\n",
    "EncImages = tf.divide((EncImagesTemp-d),(c-d))\n",
    "\n",
    "EncoderParameters = [W1,b1,W2,b2]\n",
    "    \n",
    "'''---------------------------------------Classifier Training----------------------------------------'''\n",
    "#W3,b3,W4,b4 helps in classifying utility\n",
    "W3 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b3 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W4 = tf.Variable(tf.random_normal([300, 10]))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "Hidden2 = tf.nn.relu(tf.matmul(EncImages, W3) + b3);\n",
    "OutputLayer1 = tf.matmul(Hidden2, W4) + b4;\n",
    "ClassifierParameters1 = [W3,b3,W4,b4]\n",
    "\n",
    "#W5,b5,W6,b6 helps in classifying sensitive features\n",
    "W5 = tf.Variable(tf.random_normal([784, 100], mean=0, stddev=1))\n",
    "b5 = tf.Variable(tf.random_normal([100], mean=0, stddev = 1))\n",
    "W6 = tf.Variable(tf.random_normal([100, 2]))\n",
    "b6 = tf.Variable(tf.random_normal([2]))\n",
    "\n",
    "Hidden3 = tf.nn.relu(tf.matmul(EncImages, W5) + b5);\n",
    "OutputLayer2 = tf.matmul(Hidden3, W6) + b6;\n",
    "ClassifierParameters2 = [W5,b5,W6,b6]\n",
    "\n",
    " # Optimization\n",
    "\n",
    "learning_rateU = 0.0001\n",
    "learning_rateV = 0.0002\n",
    "learning_rateE = 0.0008\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "print ('Entering Optimization')\n",
    "    \n",
    "predV = tf.nn.softmax(OutputLayer1)\n",
    "predU = tf.nn.softmax(OutputLayer2)\n",
    "\n",
    "CostV = tf.reduce_mean(-tf.reduce_sum(y[:,:10]*tf.log(tf.clip_by_value(predV,1e-10,1.0)), reduction_indices=1))\n",
    "CostU = tf.reduce_mean(-tf.reduce_sum(y[:,10:]*tf.log(tf.clip_by_value(predU,1e-10,1.0)), reduction_indices=1))\n",
    "\n",
    "cost = CostU - (alpha*CostV)\n",
    "\n",
    "\n",
    "ClassifierOptimizer1 = tf.train.AdamOptimizer(learning_rate=learning_rateV).minimize(CostV,var_list=ClassifierParameters1)\n",
    "ClassifierOptimizer2 = tf.train.AdamOptimizer(learning_rate=learning_rateU).minimize(CostU,var_list=ClassifierParameters2)\n",
    "EncoderOptimizer = tf.train.AdamOptimizer(learning_rate=learning_rateE).minimize(-cost,var_list=EncoderParameters)\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0\n",
      "Encoder cost 0.0107148846713\n",
      "Utility cost: 0.0201258347251 Private attribute cost: 0.0199695760554\n",
      "\n",
      "\n",
      "Epoch= 1\n",
      "Encoder cost 0.0109287903526\n",
      "Utility cost: 0.0190811660073 Private attribute cost: 0.020513940291\n",
      "\n",
      "\n",
      "Epoch= 2\n",
      "Encoder cost 0.0129495924169\n",
      "Utility cost: 0.0151164644415 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 3\n",
      "Encoder cost 0.0140102438493\n",
      "Utility cost: 0.0138076019287 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 4\n",
      "Encoder cost 0.0138155087558\n",
      "Utility cost: 0.0112620397048 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 5\n",
      "Encoder cost 0.0162564190951\n",
      "Utility cost: 0.00714239207181 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 6\n",
      "Encoder cost 0.0165342452309\n",
      "Utility cost: 0.00770255782387 Private attribute cost: 0.0202769348838\n",
      "\n",
      "\n",
      "Epoch= 7\n",
      "Encoder cost 0.0162875158137\n",
      "Utility cost: 0.00799399375916 Private attribute cost: 0.0144167839397\n",
      "\n",
      "\n",
      "Epoch= 8\n",
      "Encoder cost 0.0163590673967\n",
      "Utility cost: 0.0071159397472 Private attribute cost: 0.0204059340737\n",
      "\n",
      "\n",
      "Epoch= 9\n",
      "Encoder cost 0.0154405039007\n",
      "Utility cost: 0.00905820586465 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 10\n",
      "Encoder cost 0.0167458066073\n",
      "Utility cost: 0.00709541971033 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 11\n",
      "Encoder cost 0.0169728972695\n",
      "Utility cost: 0.00669842936776 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 12\n",
      "Encoder cost 0.0177926913175\n",
      "Utility cost: 0.00626035473563 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 13\n",
      "Encoder cost 0.0172646314448\n",
      "Utility cost: 0.00586112542586 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 14\n",
      "Encoder cost 0.0173740491\n",
      "Utility cost: 0.00669842936776 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 15\n",
      "Encoder cost 0.0168604417281\n",
      "Utility cost: 0.00620915759693 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 16\n",
      "Encoder cost 0.017264659188\n",
      "Utility cost: 0.00694408936934 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 17\n",
      "Encoder cost 0.0172859209234\n",
      "Utility cost: 0.00632935350591 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 18\n",
      "Encoder cost 0.0165445518494\n",
      "Utility cost: 0.00648374124007 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Epoch= 19\n",
      "Encoder cost 0.0175833754106\n",
      "Utility cost: 0.00586112542586 Private attribute cost: 0.020513938557\n",
      "\n",
      "\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "#1B\n",
    "EA = []\n",
    "PA = []\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    avg_cost3 = 0.\n",
    "    total_batch = int(int(XTrainPrime.shape[0])/batch_size)\n",
    "    print (\"Epoch=\",epoch)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c3 = sess.run([EncoderOptimizer, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "    avg_cost3 += c3 / total_batch\n",
    "    print ('Encoder cost', avg_cost3) \n",
    "    \n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c1 = sess.run([ClassifierOptimizer1, CostV], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        _, c2 = sess.run([ClassifierOptimizer2, CostU], feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "    avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "    #print (\"Detection rate of Sensitive features (on Training Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "    #print (\"Accuracy of Utility (on Training Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "    EA.append(AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "    PA.append(AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "\n",
    "    print ('Utility cost:',avg_cost1,'Private attribute cost:',avg_cost2)\n",
    "    print ('\\n')\n",
    "print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxvhkycIYY4xP/x8hlqpnHPFQcQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26e0986f898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1 = np.arange(20)\n",
    "print (len(EA))\n",
    "plt.plot(x1,EA)\n",
    "plt.plot(x1,PA)\n",
    "plt.ylabel('Detection rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Utility','Sensitive features'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection rate of Sensitive features (on Training Data): 0.5\n",
      "Accuracy of Utility (on Training Data): 0.833673\n"
     ]
    }
   ],
   "source": [
    "#1C\n",
    "\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "print (\"Detection rate of Sensitive features (on Training Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "print (\"Accuracy of Utility (on Training Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "EncTest = EncImages.eval(session=sess,feed_dict={x:XTestPrime,y:YTestPrime})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d99f26c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Temp = (EncImages.eval(session=sess,feed_dict={x:XTrainPrime[0].reshape(1,784)})).reshape((28,28))\n",
    "plt.imshow(Temp, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 1\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 2\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 3\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 4\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 5\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 6\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 7\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 8\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 9\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 10\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 11\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 12\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 13\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 14\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 15\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 16\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 17\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 18\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Epoch= 19\n",
      "Private attribute cost: 0.0782878923416\n",
      "\n",
      "\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Attacker has the capability to train further: Here the attacker just continues training\n",
    "'''\n",
    "training_epochs = 20\n",
    "learning_rateV = 0.0001\n",
    "learning_rateU = 0.0001\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    total_batch = int(int(EncTest.shape[0])/batch_size)\n",
    "    print (\"Epoch=\",epoch)\n",
    "      \n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_xs = EncTest[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTestPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c1 = sess.run([ClassifierOptimizer1, CostV], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        _, c2 = sess.run([ClassifierOptimizer2, CostU], feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "    #avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "    print ('Private attribute cost:',avg_cost2)\n",
    "    print ('\\n')\n",
    "print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection rate of Sensitive features (on Training Data): 0.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print (\"Detection rate of Sensitive features (on Training Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "#print (\"Detection rate of Sensitive features (on Training Data):\", AccuracyU.eval(session=sess,feed_dict={EncImages: EncTest, y: YTestPrime}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esha\n",
      "Epoch= 0\n",
      "Private attribute cost: 0.0660851430893\n",
      "\n",
      "\n",
      "Epoch= 1\n",
      "Private attribute cost: 0.056230931282\n",
      "\n",
      "\n",
      "Epoch= 2\n",
      "Private attribute cost: 0.0364993309975\n",
      "\n",
      "\n",
      "Epoch= 3\n",
      "Private attribute cost: 0.0251457881927\n",
      "\n",
      "\n",
      "Epoch= 4\n",
      "Private attribute cost: 0.0145295441151\n",
      "\n",
      "\n",
      "Epoch= 5\n",
      "Private attribute cost: 0.01068998456\n",
      "\n",
      "\n",
      "Epoch= 6\n",
      "Private attribute cost: 0.00976842880249\n",
      "\n",
      "\n",
      "Epoch= 7\n",
      "Private attribute cost: 0.00921287834644\n",
      "\n",
      "\n",
      "Epoch= 8\n",
      "Private attribute cost: 0.00783839583397\n",
      "\n",
      "\n",
      "Epoch= 9\n",
      "Private attribute cost: 0.00655700683594\n",
      "\n",
      "\n",
      "Epoch= 10\n",
      "Private attribute cost: 0.00515949428082\n",
      "\n",
      "\n",
      "Epoch= 11\n",
      "Private attribute cost: 0.00456365197897\n",
      "\n",
      "\n",
      "Epoch= 12\n",
      "Private attribute cost: 0.00423547714949\n",
      "\n",
      "\n",
      "Epoch= 13\n",
      "Private attribute cost: 0.00388305217028\n",
      "\n",
      "\n",
      "Epoch= 14\n",
      "Private attribute cost: 0.00344474673271\n",
      "\n",
      "\n",
      "Epoch= 15\n",
      "Private attribute cost: 0.00332902342081\n",
      "\n",
      "\n",
      "Epoch= 16\n",
      "Private attribute cost: 0.00320775270462\n",
      "\n",
      "\n",
      "Epoch= 17\n",
      "Private attribute cost: 0.00295673072338\n",
      "\n",
      "\n",
      "Epoch= 18\n",
      "Private attribute cost: 0.00269685298204\n",
      "\n",
      "\n",
      "Epoch= 19\n",
      "Private attribute cost: 0.00245415478945\n",
      "\n",
      "\n",
      "Epoch= 20\n",
      "Private attribute cost: 0.00232436776161\n",
      "\n",
      "\n",
      "Epoch= 21\n",
      "Private attribute cost: 0.00232961297035\n",
      "\n",
      "\n",
      "Epoch= 22\n",
      "Private attribute cost: 0.00233422681689\n",
      "\n",
      "\n",
      "Epoch= 23\n",
      "Private attribute cost: 0.00230448395014\n",
      "\n",
      "\n",
      "Epoch= 24\n",
      "Private attribute cost: 0.00230809032917\n",
      "\n",
      "\n",
      "Epoch= 25\n",
      "Private attribute cost: 0.00231197059155\n",
      "\n",
      "\n",
      "Epoch= 26\n",
      "Private attribute cost: 0.00231443881989\n",
      "\n",
      "\n",
      "Epoch= 27\n",
      "Private attribute cost: 0.00230794891715\n",
      "\n",
      "\n",
      "Epoch= 28\n",
      "Private attribute cost: 0.00231293052435\n",
      "\n",
      "\n",
      "Epoch= 29\n",
      "Private attribute cost: 0.00231509491801\n",
      "\n",
      "\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is an experiment not mentioned in paper. Here I assume that the attacker just received \n",
    "a bunch of encoded messages with true labels. This experiment sees if it is possible to get the images back                                                                                                                                                                                                                                         \n",
    "'''\n",
    "sess.close()\n",
    "print ('esha')\n",
    "EncImages = tf.placeholder(tf.float32,[None,784])\n",
    "learning_rateV = 0.001\n",
    "learning_rateU = 0.0001\n",
    "\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b3 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W4 = tf.Variable(tf.random_normal([300, 10]))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "Hidden2 = tf.nn.relu(tf.matmul(EncImages, W3) + b3);\n",
    "OutputLayer1 = tf.matmul(Hidden2, W4) + b4;\n",
    "ClassifierParameters1 = [W3,b3,W4,b4]\n",
    "\n",
    "#W5,b5,W6,b6 helps in classifying sensitive features\n",
    "W5 = tf.Variable(tf.random_normal([784, 100], mean=0, stddev=1))\n",
    "b5 = tf.Variable(tf.random_normal([100], mean=0, stddev = 1))\n",
    "W6 = tf.Variable(tf.random_normal([100, 2]))\n",
    "b6 = tf.Variable(tf.random_normal([2]))\n",
    "\n",
    "Hidden3 = tf.nn.relu(tf.matmul(EncImages, W5) + b5);\n",
    "OutputLayer2 = tf.matmul(Hidden3, W6) + b6;\n",
    "ClassifierParameters2 = [W5,b5,W6,b6]\n",
    "predV = tf.nn.softmax(OutputLayer1)\n",
    "predU = tf.nn.softmax(OutputLayer2)\n",
    "\n",
    "CostV = tf.reduce_mean(-tf.reduce_sum(y[:,:10]*tf.log(tf.clip_by_value(predV,1e-10,1.0)), reduction_indices=1))\n",
    "CostU = tf.reduce_mean(-tf.reduce_sum(y[:,10:]*tf.log(tf.clip_by_value(predU,1e-10,1.0)), reduction_indices=1))\n",
    "\n",
    "ClassifierOptimizer1 = tf.train.AdamOptimizer(learning_rate=learning_rateV).minimize(CostV,var_list=ClassifierParameters1)\n",
    "ClassifierOptimizer2 = tf.train.AdamOptimizer(learning_rate=learning_rateU).minimize(CostU,var_list=ClassifierParameters2)\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "training_epochs = 30\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    total_batch = int(int(EncTest.shape[0])/batch_size)\n",
    "    print (\"Epoch=\",epoch)\n",
    "      \n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_xs = EncTest[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTestPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c1 = sess.run([ClassifierOptimizer1, CostV], feed_dict={EncImages: batch_xs, y: batch_ys})\n",
    "        _, c2 = sess.run([ClassifierOptimizer2, CostU], feed_dict={EncImages: batch_xs, y: batch_ys})\n",
    "\n",
    "    avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "    print ('Private attribute cost:',avg_cost2)\n",
    "    print ('\\n')\n",
    "print (\"Optimization Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection rate of Sensitive features (on Training Data): 0.9816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Detection rate of Sensitive features (on Training Data):\", AccuracyU.eval(session=sess,feed_dict={EncImages: EncTest, y: YTestPrime}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above although initial classifier was good in the sense it could detect only 50% of the images with sensitive attributes. However, as the attacker trains the classifier more, the capability of the sensitive attrbute classifier increases and it can now detect around 70% of the images with sensitive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Optimization\n"
     ]
    }
   ],
   "source": [
    "#2A\n",
    "'''\n",
    "The architecture is same but there are some added constraints. Now all the encoded images have to have zero mean \n",
    "and unit variance. This is done to not saturate the encoder to a constant solution \n",
    "'''\n",
    "\n",
    "alpha = (1/16)\n",
    "\n",
    "    \n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 12]) # 0-9 digits recognition => 1 class\n",
    "\n",
    "\n",
    "'''-----------------------------------------Encoder Training----------------------------------------------------'''\n",
    "W1 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b1 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W2 = tf.Variable(tf.random_normal([300, 784],mean=0, stddev=1))\n",
    "b2 = tf.Variable(tf.random_normal([784],mean=0, stddev=1))\n",
    "\n",
    "Hidden1 = tf.nn.relu(tf.matmul(x, W1) + b1);\n",
    "TempLayer = tf.matmul(Hidden1, W2) + b2\n",
    "MeanTempLayer  = tf.reduce_mean(TempLayer)\n",
    "m = tf.reduce_mean(TempLayer,axis=1)\n",
    "m = tf.convert_to_tensor([m]*784)\n",
    "m = tf.reshape(m,(-1,784))\n",
    "VarTempLayer  = tf.reduce_mean((TempLayer-m)**2)\n",
    "EncImagesTemp = tf.nn.tanh(tf.matmul(Hidden1, W2) + b2);\n",
    "#These are the encodings of the images\n",
    "\n",
    "c = tf.reduce_max(EncImagesTemp)\n",
    "d = tf.reduce_min(EncImagesTemp)\n",
    "#The Encodings need to be scaled so that the final values are between 0 and 1 (like original MNIST)\n",
    "EncImages = tf.divide((EncImagesTemp-d),(c-d))\n",
    "\n",
    "EncoderParameters = [W1,b1,W2,b2]\n",
    "    \n",
    "'''---------------------------------------Classifier Training----------------------------------------'''\n",
    "#W3,b3,W4,b4 helps in classifying utility\n",
    "W3 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b3 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W4 = tf.Variable(tf.random_normal([300, 10]))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "Hidden2 = tf.nn.relu(tf.matmul(EncImages, W3) + b3);\n",
    "OutputLayer1 = tf.matmul(Hidden2, W4) + b4;\n",
    "ClassifierParameters1 = [W3,b3,W4,b4]\n",
    "\n",
    "#W5,b5,W6,b6 helps in classifying sensitive features\n",
    "W5 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b5 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W6 = tf.Variable(tf.random_normal([300, 2]))\n",
    "b6 = tf.Variable(tf.random_normal([2]))\n",
    "\n",
    "Hidden3 = tf.nn.relu(tf.matmul(EncImages, W5) + b5);\n",
    "OutputLayer2 = tf.matmul(Hidden3, W6) + b6;\n",
    "ClassifierParameters2 = [W5,b5,W6,b6]    \n",
    "  # Optimization\n",
    "learning_rateU = 0.0001\n",
    "learning_rateV = 0.0001\n",
    "learning_rateE = 0.0001\n",
    "training_epochs = 40\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "lambda1 = 0.05\n",
    "lambda2 = 0.05\n",
    "print ('Entering Optimization')\n",
    "    \n",
    "predV = tf.nn.softmax(OutputLayer1)\n",
    "predU = tf.nn.softmax(OutputLayer2)\n",
    "\n",
    "CostV = tf.reduce_mean(-tf.reduce_sum(y[:,:10]*tf.log(tf.clip_by_value(predV,1e-10,1.0)), reduction_indices=1))\n",
    "CostU = tf.reduce_mean(-tf.reduce_sum(y[:,10:]*tf.log(tf.clip_by_value(predU,1e-10,1.0)), reduction_indices=1))\n",
    "\n",
    "#Batch normalization will happen across a batch\n",
    "\n",
    "cost = CostU - (alpha*CostV) - (lambda1*MeanTempLayer) - lambda2*(VarTempLayer-1)\n",
    "\n",
    "ClassifierOptimizer1 = tf.train.AdamOptimizer(learning_rate=learning_rateV).minimize(CostV,var_list=ClassifierParameters1)\n",
    "ClassifierOptimizer2 = tf.train.AdamOptimizer(learning_rate=learning_rateU).minimize(CostU,var_list=ClassifierParameters2)\n",
    "EncoderOptimizer = tf.train.AdamOptimizer(learning_rate=learning_rateE).minimize(-cost,var_list=EncoderParameters)\n",
    "\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "#print (\"Detection rate of Sensitive features (on Test Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "#print (\"Accuracy of Utility (on Test Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "m = tf.reduce_mean(TempLayer,axis=1)\n",
    "m = tf.convert_to_tensor([m]*784)\n",
    "m = tf.reshape(m,(-1,784))\n",
    "print (m.shape)\n",
    "print (MeanTempLayer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0\n",
      "Encoder cost -0.51255049272\n",
      "Utility cost: 0.0344782326438 Private attribute cost: 0.0147616594488\n",
      "Epoch Accuracy 0.194382\n",
      "\n",
      "\n",
      "Epoch= 1\n",
      "Encoder cost -0.327788973722\n",
      "Utility cost: 0.0288886313005 Private attribute cost: 0.015831971602\n",
      "Epoch Accuracy 0.259309\n",
      "\n",
      "\n",
      "Epoch= 2\n",
      "Encoder cost -0.233642328436\n",
      "Utility cost: 0.0284949892217 Private attribute cost: 0.0183445462314\n",
      "Epoch Accuracy 0.300618\n",
      "\n",
      "\n",
      "Epoch= 3\n",
      "Encoder cost -0.178135223389\n",
      "Utility cost: 0.0293230819702 Private attribute cost: 0.0162531349876\n",
      "Epoch Accuracy 0.325564\n",
      "\n",
      "\n",
      "Epoch= 4\n",
      "Encoder cost -0.138595095548\n",
      "Utility cost: 0.0284023319591 Private attribute cost: 0.0154121052135\n",
      "Epoch Accuracy 0.337855\n",
      "\n",
      "\n",
      "Epoch= 5\n",
      "Encoder cost -0.106044242165\n",
      "Utility cost: 0.0303582000732 Private attribute cost: 0.015977973938\n",
      "Epoch Accuracy 0.349691\n",
      "\n",
      "\n",
      "Epoch= 6\n",
      "Encoder cost -0.0872513857755\n",
      "Utility cost: 0.0292016878995 Private attribute cost: 0.0162778230147\n",
      "Epoch Accuracy 0.355509\n",
      "\n",
      "\n",
      "Epoch= 7\n",
      "Encoder cost -0.068250392567\n",
      "Utility cost: 0.0296968286688 Private attribute cost: 0.0170064197887\n",
      "Epoch Accuracy 0.365945\n",
      "\n",
      "\n",
      "Epoch= 8\n",
      "Encoder cost -0.0551849434593\n",
      "Utility cost: 0.028293094635 Private attribute cost: 0.0170627108487\n",
      "Epoch Accuracy 0.372818\n",
      "\n",
      "\n",
      "Epoch= 9\n",
      "Encoder cost -0.0450640348955\n",
      "Utility cost: 0.0261555619673 Private attribute cost: 0.0173547588695\n",
      "Epoch Accuracy 0.386182\n",
      "\n",
      "\n",
      "Epoch= 10\n",
      "Encoder cost -0.0374585342407\n",
      "Utility cost: 0.026126129844 Private attribute cost: 0.0170419346203\n",
      "Epoch Accuracy 0.392527\n",
      "\n",
      "\n",
      "Epoch= 11\n",
      "Encoder cost -0.0314911998402\n",
      "Utility cost: 0.0259438584068 Private attribute cost: 0.0173634147644\n",
      "Epoch Accuracy 0.400927\n",
      "\n",
      "\n",
      "Epoch= 12\n",
      "Encoder cost -0.0263891584223\n",
      "Utility cost: 0.0235518507524 Private attribute cost: 0.0178020425276\n",
      "Epoch Accuracy 0.407745\n",
      "\n",
      "\n",
      "Epoch= 13\n",
      "Encoder cost -0.0216704698042\n",
      "Utility cost: 0.0247063654119 Private attribute cost: 0.0188091936978\n",
      "Epoch Accuracy 0.416873\n",
      "\n",
      "\n",
      "Epoch= 14\n",
      "Encoder cost -0.0156271830472\n",
      "Utility cost: 0.0242780303955 Private attribute cost: 0.0188067245483\n",
      "Epoch Accuracy 0.419964\n",
      "\n",
      "\n",
      "Epoch= 15\n",
      "Encoder cost -0.0142476966164\n",
      "Utility cost: 0.0250978938016 Private attribute cost: 0.0189093624462\n",
      "Epoch Accuracy 0.422891\n",
      "\n",
      "\n",
      "Epoch= 16\n",
      "Encoder cost -0.00974791960283\n",
      "Utility cost: 0.0248313227567 Private attribute cost: 0.0186985622753\n",
      "Epoch Accuracy 0.426582\n",
      "\n",
      "\n",
      "Epoch= 17\n",
      "Encoder cost -0.00871137272228\n",
      "Utility cost: 0.0233856305209 Private attribute cost: 0.0197091969577\n",
      "Epoch Accuracy 0.429582\n",
      "\n",
      "\n",
      "Epoch= 18\n",
      "Encoder cost -0.00606488141147\n",
      "Utility cost: 0.0231020615318 Private attribute cost: 0.0182642416521\n",
      "Epoch Accuracy 0.432345\n",
      "\n",
      "\n",
      "Epoch= 19\n",
      "Encoder cost -0.0055762759122\n",
      "Utility cost: 0.0224677554044 Private attribute cost: 0.0175035719438\n",
      "Epoch Accuracy 0.434582\n",
      "\n",
      "\n",
      "Epoch= 20\n",
      "Encoder cost -0.00460481990467\n",
      "Utility cost: 0.0226191590049 Private attribute cost: 0.0187048547918\n",
      "Epoch Accuracy 0.437891\n",
      "\n",
      "\n",
      "Epoch= 21\n",
      "Encoder cost -0.0019579818032\n",
      "Utility cost: 0.0213604580272 Private attribute cost: 0.0194675965743\n",
      "Epoch Accuracy 0.439545\n",
      "\n",
      "\n",
      "Epoch= 22\n",
      "Encoder cost 0.000237241224809\n",
      "Utility cost: 0.0216929244995 Private attribute cost: 0.0169286866622\n",
      "Epoch Accuracy 0.440655\n",
      "\n",
      "\n",
      "Epoch= 23\n",
      "Encoder cost -0.0014273816889\n",
      "Utility cost: 0.0200053925948 Private attribute cost: 0.020204634233\n",
      "Epoch Accuracy 0.441\n",
      "\n",
      "\n",
      "Epoch= 24\n",
      "Encoder cost 0.0017816474221\n",
      "Utility cost: 0.0207387872176 Private attribute cost: 0.0199898078225\n",
      "Epoch Accuracy 0.441873\n",
      "\n",
      "\n",
      "Epoch= 25\n",
      "Encoder cost 0.0032096377286\n",
      "Utility cost: 0.0194505743547 Private attribute cost: 0.020372876254\n",
      "Epoch Accuracy 0.446055\n",
      "\n",
      "\n",
      "Epoch= 26\n",
      "Encoder cost 0.00415957537564\n",
      "Utility cost: 0.0193105697632 Private attribute cost: 0.0197479941628\n",
      "Epoch Accuracy 0.443382\n",
      "\n",
      "\n",
      "Epoch= 27\n",
      "Encoder cost 0.00464701739225\n",
      "Utility cost: 0.0188312894648 Private attribute cost: 0.0208271633495\n",
      "Epoch Accuracy 0.446982\n",
      "\n",
      "\n",
      "Epoch= 28\n",
      "Encoder cost 0.00617592204701\n",
      "Utility cost: 0.0197191221064 Private attribute cost: 0.0200856572931\n",
      "Epoch Accuracy 0.4464\n",
      "\n",
      "\n",
      "Epoch= 29\n",
      "Encoder cost 0.00556613228538\n",
      "Utility cost: 0.0204202721336 Private attribute cost: 0.020753068057\n",
      "Epoch Accuracy 0.443036\n",
      "\n",
      "\n",
      "Epoch= 30\n",
      "Encoder cost 0.00688390471719\n",
      "Utility cost: 0.0202192653309 Private attribute cost: 0.0200812547857\n",
      "Epoch Accuracy 0.445218\n",
      "\n",
      "\n",
      "Epoch= 31\n",
      "Encoder cost 0.00590282006697\n",
      "Utility cost: 0.0206398599798 Private attribute cost: 0.0183687851646\n",
      "Epoch Accuracy 0.443073\n",
      "\n",
      "\n",
      "Epoch= 32\n",
      "Encoder cost 0.00563634092158\n",
      "Utility cost: 0.0202720815485 Private attribute cost: 0.0194366437739\n",
      "Epoch Accuracy 0.434618\n",
      "\n",
      "\n",
      "Epoch= 33\n",
      "Encoder cost 0.00788981871171\n",
      "Utility cost: 0.0206368429011 Private attribute cost: 0.0188067800348\n",
      "Epoch Accuracy 0.435927\n",
      "\n",
      "\n",
      "Epoch= 34\n",
      "Encoder cost 0.00711637410251\n",
      "Utility cost: 0.0212120056152 Private attribute cost: 0.0201582215049\n",
      "Epoch Accuracy 0.432836\n",
      "\n",
      "\n",
      "Epoch= 35\n",
      "Encoder cost 0.00818225600503\n",
      "Utility cost: 0.0210540268638 Private attribute cost: 0.0197455406189\n",
      "Epoch Accuracy 0.432309\n",
      "\n",
      "\n",
      "Epoch= 36\n",
      "Encoder cost 0.00843881346963\n",
      "Utility cost: 0.0203071715615 Private attribute cost: 0.0187626058405\n",
      "Epoch Accuracy 0.440836\n",
      "\n",
      "\n",
      "Epoch= 37\n",
      "Encoder cost 0.00850661104376\n",
      "Utility cost: 0.0204821274497 Private attribute cost: 0.0214071828669\n",
      "Epoch Accuracy 0.442236\n",
      "\n",
      "\n",
      "Epoch= 38\n",
      "Encoder cost 0.0102600349079\n",
      "Utility cost: 0.0210292590748 Private attribute cost: 0.020459504561\n",
      "Epoch Accuracy 0.4408\n",
      "\n",
      "\n",
      "Epoch= 39\n",
      "Encoder cost 0.00992082162337\n",
      "Utility cost: 0.0213462482799 Private attribute cost: 0.0211455518549\n",
      "Epoch Accuracy 0.438309\n",
      "\n",
      "\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "#1B\n",
    "EA = []\n",
    "PA = []\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    avg_cost3 = 0.\n",
    "    total_batch = int(int(XTrainPrime.shape[0])/batch_size)\n",
    "    print (\"Epoch=\",epoch)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c3 = sess.run([EncoderOptimizer, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "    avg_cost3 += c3 / total_batch\n",
    "    print ('Encoder cost', avg_cost3) \n",
    "    \n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c1 = sess.run([ClassifierOptimizer1, CostV], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        _, c2 = sess.run([ClassifierOptimizer2, CostU], feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "    avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "    print ('Utility cost:',avg_cost1,'Private attribute cost:',avg_cost2)\n",
    "    EpochAccuracy = AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime})\n",
    "    print ('Epoch Accuracy',EpochAccuracy)\n",
    "    EA.append(EpochAccuracy)\n",
    "    PA.append(AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "#     if (EpochAccuracy > 0.6):\n",
    "#         #print ('yippie')\n",
    "#         learning_rateU = 0.001\n",
    "#         learning_rateV = 0.0005\n",
    "#         learning_rateE = 0.001\n",
    "#     if (EpochAccuracy > 0.8):\n",
    "#         #print ('yippie')\n",
    "#         learning_rateU = 0.0001\n",
    "#         learning_rateV = 0.0001\n",
    "#         learning_rateE = 0.0005\n",
    "#         alpha = 1.5\n",
    "    print ('\\n')\n",
    "print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26dc6cb1cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1 = np.arange(40)\n",
    "print (len(EA))\n",
    "plt.plot(x1,EA)\n",
    "plt.plot(x1,PA)\n",
    "plt.ylabel('Detection rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Utility','Sensitive features'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_152' with dtype float and shape [?,784]\n\t [[Node: Placeholder_152 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_152', defined at:\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipython-6.2.0-py3.5.egg\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipython-6.2.0-py3.5.egg\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipython-6.2.0-py3.5.egg\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-414-27c7ada08a98>\", line 10, in <module>\n    x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_152' with dtype float and shape [?,784]\n\t [[Node: Placeholder_152 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_152' with dtype float and shape [?,784]\n\t [[Node: Placeholder_152 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-430-499435830853>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mbatch_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXTrainPrime\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYTrainPrime\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEncoderOptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mavg_cost3\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc3\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Encoder cost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_cost3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_152' with dtype float and shape [?,784]\n\t [[Node: Placeholder_152 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_152', defined at:\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipython-6.2.0-py3.5.egg\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipython-6.2.0-py3.5.egg\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipython-6.2.0-py3.5.egg\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-414-27c7ada08a98>\", line 10, in <module>\n    x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"c:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_152' with dtype float and shape [?,784]\n\t [[Node: Placeholder_152 = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rateU = 0.0001\n",
    "learning_rateV = 0.0003\n",
    "learning_rateE = 0.0005\n",
    "training_epochs = 10\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    avg_cost3 = 0.\n",
    "    total_batch = int(int(XTrainPrime.shape[0])/batch_size)\n",
    "    print (\"Epoch=\",epoch)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c3 = sess.run([EncoderOptimizer, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "    avg_cost3 += c3 / total_batch\n",
    "    print ('Encoder cost', avg_cost3) \n",
    "    \n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c1 = sess.run([ClassifierOptimizer1, CostV], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        _, c2 = sess.run([ClassifierOptimizer2, CostU], feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "    avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "    print ('Utility cost:',avg_cost1,'Private attribute cost:',avg_cost2)\n",
    "    EpochAccuracy = AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime})\n",
    "    print ('Epoch Accuracy',EpochAccuracy)\n",
    "    EA.append(EpochAccuracy)\n",
    "    PA.append(AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "print ('Optimization finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written report till here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection rate of Sensitive features (on Training Data): 0.5\n",
      "Accuracy of Utility (on Training Data): 0.833673\n"
     ]
    }
   ],
   "source": [
    "#2C\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "print (\"Detection rate of Sensitive features (on Training Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "print (\"Accuracy of Utility (on Training Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Utility is improving in the previous method, the encoded images look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26dc2e50e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nENTfAXmPd9a1NbGsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26df87fab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Temp = (EncImages.eval(session=sess,feed_dict={x:XTrainPrime[0].reshape(1,784)})).reshape((28,28))\n",
    "plt.imshow(Temp, cmap='gray')\n",
    "plt.show()\n",
    "Temp2 = XTrainPrime[0].reshape((28,28))\n",
    "plt.imshow(Temp2, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 1\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 2\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 3\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 4\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 5\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 6\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 7\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 8\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 9\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 10\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 11\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 12\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 13\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 14\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 15\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 16\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 17\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 18\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 19\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Optimization Finished!\n",
      "Detection rate of Sensitive features (on Training Data): 0.4\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 20\n",
    "learning_rateV = 0.0001\n",
    "learning_rateU = 0.0001\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    total_batch = int(int(EncTest.shape[0])/batch_size)\n",
    "    print (\"Epoch=\",epoch)\n",
    "      \n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_xs = EncTest[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTestPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c1 = sess.run([ClassifierOptimizer1, CostV], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        _, c2 = sess.run([ClassifierOptimizer2, CostU], feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "    #avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "    print ('Private attribute cost:',avg_cost2)\n",
    "    print ('\\n')\n",
    "print (\"Optimization Finished!\")\n",
    "\n",
    "print (\"Detection rate of Sensitive features (on Training Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esha\n",
      "Epoch= 0\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 1\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 2\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 3\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 4\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 5\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 6\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 7\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 8\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 9\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 10\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 11\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 12\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 13\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 14\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 15\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 16\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 17\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 18\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Epoch= 19\n",
      "Private attribute cost: 0.112826662064\n",
      "\n",
      "\n",
      "Optimization Finished!\n",
      "Detection rate of Sensitive features (on Training Data): 0.4\n"
     ]
    }
   ],
   "source": [
    "sess.close()\n",
    "print ('esha')\n",
    "EncImages = tf.placeholder(tf.float32,[None,784])\n",
    "learning_rateV = 0.001\n",
    "learning_rateU = 0.0001\n",
    "\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b3 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W4 = tf.Variable(tf.random_normal([300, 10]))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "Hidden2 = tf.nn.relu(tf.matmul(EncImages, W3) + b3);\n",
    "OutputLayer1 = tf.matmul(Hidden2, W4) + b4;\n",
    "ClassifierParameters1 = [W3,b3,W4,b4]\n",
    "\n",
    "#W5,b5,W6,b6 helps in classifying sensitive features\n",
    "W5 = tf.Variable(tf.random_normal([784, 100], mean=0, stddev=1))\n",
    "b5 = tf.Variable(tf.random_normal([100], mean=0, stddev = 1))\n",
    "W6 = tf.Variable(tf.random_normal([100, 2]))\n",
    "b6 = tf.Variable(tf.random_normal([2]))\n",
    "\n",
    "Hidden3 = tf.nn.relu(tf.matmul(EncImages, W5) + b5);\n",
    "OutputLayer2 = tf.matmul(Hidden3, W6) + b6;\n",
    "ClassifierParameters2 = [W5,b5,W6,b6]\n",
    "predV = tf.nn.softmax(OutputLayer1)\n",
    "predU = tf.nn.softmax(OutputLayer2)\n",
    "\n",
    "CostV = tf.reduce_mean(-tf.reduce_sum(y[:,:10]*tf.log(tf.clip_by_value(predV,1e-10,1.0)), reduction_indices=1))\n",
    "CostU = tf.reduce_mean(-tf.reduce_sum(y[:,10:]*tf.log(tf.clip_by_value(predU,1e-10,1.0)), reduction_indices=1))\n",
    "\n",
    "ClassifierOptimizer1 = tf.train.AdamOptimizer(learning_rate=learning_rateV).minimize(CostV,var_list=ClassifierParameters1)\n",
    "ClassifierOptimizer2 = tf.train.AdamOptimizer(learning_rate=learning_rateU).minimize(CostU,var_list=ClassifierParameters2)\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "training_epochs = 20\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    total_batch = int(int(EncTest.shape[0])/batch_size)\n",
    "    print (\"Epoch=\",epoch)\n",
    "      \n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_xs = EncTest[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTestPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c1 = sess.run([ClassifierOptimizer1, CostV], feed_dict={EncImages: batch_xs, y: batch_ys})\n",
    "        _, c2 = sess.run([ClassifierOptimizer2, CostU], feed_dict={EncImages: batch_xs, y: batch_ys})\n",
    "\n",
    "    avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "    print ('Private attribute cost:',avg_cost2)\n",
    "    print ('\\n')\n",
    "print (\"Optimization Finished!\")\n",
    "\n",
    "print (\"Detection rate of Sensitive features (on Training Data):\", AccuracyU.eval(session=sess,feed_dict={EncImages: EncTest, y: YTestPrime}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "No. of images changed are 7500\n",
      "No. of images changed are 7000\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "XTrain = mnist.train.images\n",
    "YTrain = mnist.train.labels\n",
    "XTest = mnist.test.images\n",
    "YTest = mnist.test.labels\n",
    "def TransformMNIST (Percentage,OrigX,OrigY):\n",
    "\n",
    "    #Choose random images to insert sensitive information\n",
    "    SelectedImages = np.random.choice(int(OrigX.shape[0]),int((Percentage/100)*OrigX.shape[0]),replace=False) \n",
    "    print ('No. of images changed are', SelectedImages.shape[0]) #Choose random images to insert sensitive information\n",
    "\n",
    "    SubX = OrigX[SelectedImages]\n",
    "    SubX[:,729] = 1\n",
    "    \n",
    "    #Uncomment the following 4 lines if you want the flower as sensitive feature\n",
    "    SubX[:,700] = 1\n",
    "    SubX[:,702] = 1\n",
    "    SubX[:,756] = 1\n",
    "    SubX[:,758] = 1\n",
    "    \n",
    "    SubY = OrigY[SelectedImages]\n",
    "    SenYCol = np.zeros((OrigY.shape[0],2))\n",
    "    NewY = np.concatenate((OrigY,SenYCol),axis=1)\n",
    "\n",
    "    for num,i in enumerate(SelectedImages):\n",
    "        OrigX[i]=SubX[num]\n",
    "        NewY[i][11]=1\n",
    "    NewX = OrigX\n",
    "    for i in range(int(OrigX.shape[0])):\n",
    "        if i not in SelectedImages:\n",
    "            NewY[i][10]=1\n",
    "    return (SelectedImages, NewX,NewY)\n",
    "\n",
    "s,XTrainPrime, YTrainPrime = TransformMNIST(50,XTrain[:15000],YTrain[:15000])\n",
    "_,XTestPrime, YTestPrime = TransformMNIST(70,XTest,YTest)\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "XTrain = mnist.train.images\n",
    "YTrain = mnist.train.labels\n",
    "XTest = mnist.test.images\n",
    "YTest = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuhGTcEYTzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26da9feec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d99dcefd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=s[0]\n",
    "X=XTrainPrime[n]\n",
    "TempImage = X.reshape((28,28))\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()\n",
    "X1=XTrain[n]\n",
    "TempImage1 = X1.reshape((28,28))\n",
    "plt.imshow(TempImage1, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=s[0]\n",
    "X=XTrainPrime[n]\n",
    "TempImage = X.reshape((28,28))\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Optimization\n",
      "Tensor(\"Mean_544:0\", shape=(), dtype=float32) Tensor(\"Mean_546:0\", shape=(), dtype=float32) Tensor(\"Sqrt_19:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The architecture is same but there are some added constraints. Now all the encoded images have to have zero mean \n",
    "and unit variance. This is done to not saturate the encoder to a constant solution and will try to look similar \n",
    "to the original digit without any attribute\n",
    "'''\n",
    "\n",
    "alpha = (1)\n",
    "\n",
    "    \n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 12]) # 0-9 digits recognition => 1 class\n",
    "\n",
    "\n",
    "'''-----------------------------------------Encoder Training----------------------------------------------------'''\n",
    "W1 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b1 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W2 = tf.Variable(tf.random_normal([300, 784],mean=0, stddev=1))\n",
    "b2 = tf.Variable(tf.random_normal([784],mean=0, stddev=1))\n",
    "\n",
    "Hidden1 = tf.nn.relu(tf.matmul(x, W1) + b1);\n",
    "TempLayer = tf.matmul(Hidden1, W2) + b2\n",
    "MeanTempLayer  = tf.reduce_mean(TempLayer)\n",
    "m = tf.reduce_mean(TempLayer,axis=1)\n",
    "m = tf.convert_to_tensor([m]*784)\n",
    "m = tf.reshape(m,(-1,784))\n",
    "VarTempLayer  = tf.reduce_mean((TempLayer-m)**2)\n",
    "EncImagesTemp = tf.nn.tanh(tf.matmul(Hidden1, W2) + b2);\n",
    "#These are the encodings of the images\n",
    "\n",
    "c = tf.reduce_max(EncImagesTemp)\n",
    "d = tf.reduce_min(EncImagesTemp)\n",
    "#The Encodings need to be scaled so that the final values are between 0 and 1 (like original MNIST)\n",
    "EncImages = tf.divide((EncImagesTemp-d),(c-d))\n",
    "L2Norm = tf.sqrt(tf.reduce_sum((EncImages - x)**2))\n",
    "\n",
    "EncoderParameters = [W1,b1,W2,b2]\n",
    "    \n",
    "'''---------------------------------------Classifier Training----------------------------------------'''\n",
    "#W3,b3,W4,b4 helps in classifying utility\n",
    "W3 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b3 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W4 = tf.Variable(tf.random_normal([300, 10]))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "Hidden2 = tf.nn.relu(tf.matmul(EncImages, W3) + b3);\n",
    "OutputLayer1 = tf.matmul(Hidden2, W4) + b4;\n",
    "ClassifierParameters1 = [W3,b3,W4,b4]\n",
    "\n",
    "#W5,b5,W6,b6 helps in classifying sensitive features\n",
    "W5 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b5 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W6 = tf.Variable(tf.random_normal([300, 2]))\n",
    "b6 = tf.Variable(tf.random_normal([2]))\n",
    "\n",
    "Hidden3 = tf.nn.relu(tf.matmul(EncImages, W5) + b5);\n",
    "OutputLayer2 = tf.matmul(Hidden3, W6) + b6;\n",
    "ClassifierParameters2 = [W5,b5,W6,b6]    \n",
    "  # Optimization\n",
    "learning_rateU = 0.0001\n",
    "learning_rateV = 0.0003\n",
    "learning_rateE = 0.0005\n",
    "training_epochs = 30\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "lambda1 = 0.05\n",
    "lambda2 = 0.05\n",
    "lambda3 = 0.2\n",
    "print ('Entering Optimization')\n",
    "    \n",
    "predV = tf.nn.softmax(OutputLayer1)\n",
    "predU = tf.nn.softmax(OutputLayer2)\n",
    "\n",
    "CostV = tf.reduce_mean(-tf.reduce_sum(y[:,:10]*tf.log(tf.clip_by_value(predV,1e-10,1.0)), reduction_indices=1))\n",
    "CostU = tf.reduce_mean(-tf.reduce_sum(y[:,10:]*tf.log(tf.clip_by_value(predU,1e-10,1.0)), reduction_indices=1))\n",
    "\n",
    "#Batch normalization will happen across a batch\n",
    "\n",
    "cost = CostU - (alpha*CostV) - (lambda1*MeanTempLayer) - lambda2*(VarTempLayer-1) - lambda3*(L2Norm)\n",
    "print (MeanTempLayer,VarTempLayer,L2Norm)\n",
    "ClassifierOptimizer1 = tf.train.AdamOptimizer(learning_rate=learning_rateV).minimize(CostV,var_list=ClassifierParameters1)\n",
    "ClassifierOptimizer2 = tf.train.AdamOptimizer(learning_rate=learning_rateU).minimize(CostU,var_list=ClassifierParameters2)\n",
    "EncoderOptimizer = tf.train.AdamOptimizer(learning_rate=learning_rateE).minimize(-cost,var_list=EncoderParameters)\n",
    "\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "#print (\"Detection rate of Sensitive features (on Test Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "#print (\"Accuracy of Utility (on Test Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0\n",
      "Encoder cost -0.00604806587913\n",
      "Utility cost: 0.00209325911782 Private attribute cost: 0.00251191104542\n",
      "Epoch Accuracy 0.369291\n",
      "Accuracy with which sensitive features are detected 0.499782\n",
      "\n",
      "\n",
      "Epoch= 1\n",
      "Encoder cost -0.00306634348089\n",
      "Utility cost: 0.00209325911782 Private attribute cost: 0.00251191104542\n",
      "Epoch Accuracy 0.426509\n",
      "Accuracy with which sensitive features are detected 0.499982\n",
      "\n",
      "\n",
      "Epoch= 2\n",
      "Encoder cost -0.00186189478094\n",
      "Utility cost: 0.00167460736361 Private attribute cost: 0.00251191104542\n",
      "Epoch Accuracy 0.411582\n",
      "Accuracy with which sensitive features are detected 0.500018\n",
      "\n",
      "\n",
      "Epoch= 3\n",
      "Encoder cost -0.00141085485979\n",
      "Utility cost: 0.00167460736361 Private attribute cost: 0.00251191104542\n",
      "Epoch Accuracy 0.379891\n",
      "Accuracy with which sensitive features are detected 0.499964\n",
      "\n",
      "\n",
      "Epoch= 4\n",
      "Encoder cost -0.00161963272095\n",
      "Utility cost: 0.00251191104542 Private attribute cost: 0.00251191104542\n",
      "Epoch Accuracy 0.366273\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "Epoch= 5\n",
      "Encoder cost -0.00189877111262\n",
      "Utility cost: 0.00334921472723 Private attribute cost: 0.00251191104542\n",
      "Epoch Accuracy 0.348364\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "Epoch= 6\n",
      "Encoder cost -0.00271575580944\n",
      "Utility cost: 0.00293056279963 Private attribute cost: 0.00251191104542\n",
      "Epoch Accuracy 0.350655\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "Epoch= 7\n",
      "Encoder cost -0.00138899152929\n",
      "Utility cost: 0.00335477724942 Private attribute cost: 0.00251191104542\n",
      "Epoch Accuracy 0.342418\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "Epoch= 8\n",
      "Encoder cost -0.00174558206038\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-445-7e485d1792bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYTrial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mClassifierOptimizer1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCostV\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mClassifierOptimizer2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCostU\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[1;31m#print (c1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m#print (c2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#1B\n",
    "EA = []\n",
    "PA = []\n",
    "alpha = 0.75\n",
    "training_epochs = 20\n",
    "XTrial = XTrainPrime\n",
    "YTrial = YTrainPrime\n",
    "batch_size = 10\n",
    "learning_rateU = 0.0001\n",
    "learning_rateV = 0.0001\n",
    "learning_rateE = 0.0005\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    avg_cost3 = 0.\n",
    "    total_batch = int(int(XTrial.shape[0])/batch_size)\n",
    "    print (\"Epoch=\",epoch)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs = XTrial[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrial[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c3 = sess.run([EncoderOptimizer, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        #print (c3)\n",
    "    avg_cost3 += c3 / total_batch\n",
    "    print ('Encoder cost', avg_cost3) \n",
    "    \n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_xs = XTrial[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrial[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c1 = sess.run([ClassifierOptimizer1, CostV], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        _, c2 = sess.run([ClassifierOptimizer2, CostU], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        #print (c1)\n",
    "        #print (c2)\n",
    "    avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "    print ('Utility cost:',avg_cost1,'Private attribute cost:',avg_cost2)\n",
    "    EpochAccuracy = AccuracyV.eval(session=sess,feed_dict={x: XTrial, y: YTrial})\n",
    "    SenAcc = AccuracyU.eval(session=sess,feed_dict={x: XTrial, y: YTrial})\n",
    "    print ('Epoch Accuracy',EpochAccuracy)\n",
    "    print ('Accuracy with which sensitive features are detected', SenAcc)\n",
    "    EA.append(AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "    PA.append(AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "#     if (EpochAccuracy > 0.6):\n",
    "#         #print ('yippie')\n",
    "#         learning_rateU = 0.001\n",
    "#         learning_rateV = 0.0005\n",
    "#         learning_rateE = 0.001\n",
    "#     if (EpochAccuracy > 0.8):\n",
    "#         #print ('yippie')\n",
    "#         learning_rateU = 0.0001\n",
    "#         learning_rateV = 0.0001\n",
    "#         learning_rateE = 0.0005\n",
    "#         alpha = 1.5\n",
    "    print ('\\n')\n",
    "print (\"Optimization Finished!\")\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "#print ((tf.argmax(y[:,10:], 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "#a=(tf.argmax(predU, 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime})\n",
    "#print (XTestPrime.shape)\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "print (\"Detection rate of Sensitive features (on Test Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTrial, y: YTrial}))\n",
    "print (\"Accuracy of Utility (on Training Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTrial, y: YTrial}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOEHgiL8QFCEHwjqf2ALW5hVaQo4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26e09874ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Temp = (EncImages.eval(session=sess,feed_dict={x:XTrainPrime[1].reshape(1,784)})).reshape((28,28))\n",
    "plt.imshow(Temp, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection rate of Sensitive features (on Test Data): 0.4706\n",
      "Accuracy of Utility (on Test Data): 0.0947\n"
     ]
    }
   ],
   "source": [
    "#3C\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "#print ((tf.argmax(y[:,10:], 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "#a=(tf.argmax(predU, 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime})\n",
    "#print (XTestPrime.shape)\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "print (\"Detection rate of Sensitive features (on Test Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "print (\"Accuracy of Utility (on Test Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New encoded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n=s[0]\n",
    "temp1 = XTrainPrime[n].reshape((1,784))\n",
    "temp2 = temp1.reshape((28,28))\n",
    "X=EncImages.eval(session=sess,feed_dict={x:temp1})\n",
    "TempImage = X.reshape((28,28))\n",
    "plt.imshow(temp2, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()\n",
    "distance = np.sqrt(np.sum((X-temp1)**2))\n",
    "print (\"Difference between encoded and original image is\", distance)\n",
    "# result shows this needs improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X=EncImages.eval(session=sess,feed_dict={x:temp1})\n",
    "NewX = X[0]\n",
    "#print (NewX)\n",
    "for num, pixel in enumerate(X[0]):\n",
    "    if pixel <=2e-1:\n",
    "        #print (num)\n",
    "        NewX[num] = 0\n",
    "    elif pixel > 3e-1 and pixel <= 5e-1:\n",
    "        NewX[num] = 0.5\n",
    "        #print ('yes')\n",
    "    else:\n",
    "        NewX[num] = 1\n",
    "TempImage = NewX.reshape((28,28))\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=EncImages.eval(session=sess,feed_dict={x:temp1})\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The small amount of features selected 5/784 is not enough to make the neural network understand that there is some special feature residing\n",
    "So I make the sensitive features a little more broad.\n",
    "Here I transform the MNIST dataset for a few of them to have opposite background as the original\n",
    "'''\n",
    "XTrain = mnist.train.images[:1000]\n",
    "YTrain = mnist.train.labels[:1000]\n",
    "XTest = mnist.test.images[:1000]\n",
    "YTest = mnist.test.labels[:1000]\n",
    "def BWTransformMNIST (Percentage,OrigX,OrigY):\n",
    "    SelectedImages = np.random.choice(int(OrigX.shape[0]),int((Percentage/100)*OrigX.shape[0]),replace=False) #Choose random images to insert sensitive information\n",
    "    print ('No. of images changed are', SelectedImages.shape[0])\n",
    "    SubX = 1-OrigX[SelectedImages]\n",
    "    \n",
    "    \n",
    "    SubY = OrigY[SelectedImages]\n",
    "    SenYCol = np.zeros((OrigY.shape[0],2))\n",
    "    NewY = np.concatenate((OrigY,SenYCol),axis=1)\n",
    "\n",
    "    for num,i in enumerate(SelectedImages):\n",
    "        OrigX[i]=SubX[num]\n",
    "        NewY[i][11]=1\n",
    "    NewX = OrigX\n",
    "    for i in range(int(OrigX.shape[0])):\n",
    "        if i not in SelectedImages:\n",
    "            NewY[i][10]=1\n",
    "    return (SelectedImages, NewX,NewY)\n",
    "\n",
    "s,XTrainPrime, YTrainPrime = BWTransformMNIST(80,XTrain,YTrain)\n",
    "_,XTestPrime, YTestPrime = BWTransformMNIST(30,XTest,YTest)\n",
    "XTrain = mnist.train.images[:1000]\n",
    "YTrain = mnist.train.labels[:1000]\n",
    "XTest = mnist.test.images[:1000]\n",
    "YTest = mnist.test.labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=s[0]\n",
    "X=XTrainPrime[n]\n",
    "TempImage = X.reshape((28,28))\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One\n",
      "Entering Optimization\n"
     ]
    }
   ],
   "source": [
    "#4A\n",
    "#Use CNN instead of regular DNN\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 12]) # 0-9 digits recognition => 1 class + verification of sensitive information\n",
    "\n",
    "\n",
    "'''-----------------------------------------Encoder Training----------------------------------------------------'''\n",
    "input_layer = tf.reshape(x,[-1, 28, 28, 1])    #-1 infers the shape according to the batch size user gives\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "Econv1Temp = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=1,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"same\",\n",
    "    activation=None,\n",
    "    reuse=None,\n",
    "    name=None)\n",
    "    \n",
    "Econv1BN = tf.layers.batch_normalization(\n",
    "    inputs=Econv1Temp,\n",
    "    axis=-1,\n",
    "    momentum=0.99,\n",
    "    epsilon=0.001,\n",
    "    reuse=None)\n",
    "    \n",
    "Econv1 = tf.nn.relu(Econv1BN)\n",
    "\n",
    "Econv2Temp = tf.layers.conv2d(\n",
    "    inputs=Econv1,\n",
    "    filters=1,\n",
    "    kernel_size=[3, 3],\n",
    "    padding=\"same\",\n",
    "    activation=None,\n",
    "    reuse=None)\n",
    "    \n",
    "Econv2BN = tf.layers.batch_normalization(\n",
    "    inputs=Econv2Temp,\n",
    "    axis=-1,\n",
    "    momentum=0.99,\n",
    "    epsilon=0.001,\n",
    "    reuse=None)\n",
    "    \n",
    "EncImagesTemp = tf.nn.relu(Econv2BN)\n",
    "\n",
    "c = tf.reduce_max(EncImagesTemp)\n",
    "d = tf.reduce_min(EncImagesTemp)\n",
    "#The Encodings need to be scaled so that the final values are between 0 and 1 (like original MNIST)\n",
    "EncImages = tf.divide((EncImagesTemp-d),(c-d))\n",
    "#EncoderParameters = [W1,b1,W2,b2,W3,b3]\n",
    "EncoderParameters = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    \n",
    "'''---------------------------------------Classifier Training----------------------------------------'''\n",
    "InputLayer = tf.reshape(EncImages,[-1, 28, 28, 1]) \n",
    "print (\"One\")\n",
    "    #-1 infers the shape according to the batch size user gives\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "Cconv1Temp = tf.layers.conv2d(\n",
    "inputs=InputLayer,\n",
    "filters=1,\n",
    "kernel_size=[3, 3],\n",
    "padding=\"same\",\n",
    "activation=None)\n",
    "    \n",
    "Cconv1BN = tf.layers.batch_normalization(\n",
    "inputs=Cconv1Temp,\n",
    "axis=-1,\n",
    "momentum=0.99,\n",
    "epsilon=0.001,trainable=True)\n",
    "    \n",
    "Cconv1 = tf.nn.relu(Cconv1BN)\n",
    "Cfc3 = tf.layers.dense(inputs=Cconv1,units=1000,activation=tf.nn.relu)\n",
    "dim = int(Cfc3.shape[1]*Cfc3.shape[2]*Cfc3.shape[3])\n",
    "Cfc3Flat = tf.reshape(Cfc3,[-1,dim])\n",
    "    #print (fc3Flat.shape)\n",
    "    \n",
    "  # Fully Connected Layer #1\n",
    "OutputLayer1 = tf.layers.dense(inputs=Cfc3Flat,units=10,activation=None)\n",
    "EncoderLen = len(EncoderParameters)\n",
    "ClassifierParameters1 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)[EncoderLen:]\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "Cconv2Temp = tf.layers.conv2d(\n",
    "inputs=InputLayer,\n",
    "filters=1,\n",
    "kernel_size=[3, 3],\n",
    "padding=\"same\",\n",
    "activation=None)\n",
    "    \n",
    "Cconv2BN = tf.layers.batch_normalization(\n",
    "inputs=Cconv1Temp,\n",
    "axis=-1,\n",
    "momentum=0.99,\n",
    "epsilon=0.001,trainable=True)\n",
    "    \n",
    "Cconv2 = tf.nn.relu(Cconv1BN)\n",
    "Cfc3 = tf.layers.dense(inputs=Cconv2,units=300,activation=tf.nn.relu)\n",
    "dim = int(Cfc3.shape[1]*Cfc3.shape[2]*Cfc3.shape[3])\n",
    "Cfc3Flat = tf.reshape(Cfc3,[-1,dim])\n",
    "    #print (fc3Flat.shape)\n",
    "    \n",
    "  # Fully Connected Layer #1\n",
    "OutputLayer2 = tf.layers.dense(inputs=Cfc3Flat,units=2,activation=None)\n",
    "Classifier1Len = len(ClassifierParameters1)\n",
    "ClassifierParameters2 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)[Classifier1Len:]\n",
    "\n",
    "\n",
    "#print (ClassifierParameters)\n",
    "    \n",
    "  # Optimization\n",
    "learning_rateU = 0.0001\n",
    "learning_rateV = 0.0001\n",
    "learning_rateE1 = 0.0001\n",
    "training_epochs = 10\n",
    "batch_size = 100\n",
    "alpha = 1/16\n",
    "beta = 1\n",
    "print ('Entering Optimization')\n",
    "    \n",
    "predV = tf.nn.tanh(OutputLayer1)\n",
    "predU = tf.nn.tanh(OutputLayer2)\n",
    "\n",
    "CostV = tf.reduce_mean(-tf.reduce_sum(y[:,:10]*tf.log(tf.clip_by_value(predV,1e-5,1.0)), reduction_indices=1))\n",
    "CostU = tf.reduce_mean(-tf.reduce_sum(y[:,10:]*tf.log(tf.clip_by_value(predU,1e-5,1.0)), reduction_indices=1))\n",
    "\n",
    "\n",
    "cost = CostU - (alpha*CostV)\n",
    "#LookSimilarCost = tf.sqrt(tf.reduce_sum((x-EncImages)**2))\n",
    "\n",
    "ClassifierOptimizer1 = tf.train.AdamOptimizer(learning_rate=learning_rateU).minimize(CostU,var_list=ClassifierParameters2)\n",
    "ClassifierOptimizer2 = tf.train.AdamOptimizer(learning_rate=learning_rateV).minimize(CostV,var_list=ClassifierParameters1)\n",
    "EncoderOptimizer1 = tf.train.AdamOptimizer(learning_rate=learning_rateE1).minimize(-cost,var_list=EncoderParameters)\n",
    "#EncoderOptimizer2 = tf.train.AdamOptimizer(learning_rate=learning_rateE2).minimize(-cost,var_list=EncoderParameters)\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "#print ((tf.argmax(y[:,10:], 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "#a=(tf.argmax(predU, 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime})\n",
    "#print (XTestPrime.shape)\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0 \n",
      "\n",
      "0.0177874946594\n",
      "2.70909883759e-06 7.23168116317e-07\n",
      "Detection rate of Sensitive features (on Test Data): 0.3857\n",
      "Accuracy of Utility (on Test Data): 0.1135\n",
      "Epoch= 1 \n",
      "\n",
      "2.68004241992e-06\n",
      "5.77468202788e-07 1.66490949182e-07\n",
      "Detection rate of Sensitive features (on Test Data): 0.3841\n",
      "Accuracy of Utility (on Test Data): 0.1135\n",
      "Epoch= 2 \n",
      "\n",
      "5.67494214258e-07\n",
      "2.18969296177e-07 6.74598016882e-08\n",
      "Detection rate of Sensitive features (on Test Data): 0.3892\n",
      "Accuracy of Utility (on Test Data): 0.1135\n",
      "Epoch= 3 \n",
      "\n",
      "2.14991781501e-07\n",
      "1.0410847608e-07 3.35816168279e-08\n",
      "Detection rate of Sensitive features (on Test Data): 0.393\n",
      "Accuracy of Utility (on Test Data): 0.1135\n",
      "Epoch= 4 \n",
      "\n",
      "1.02133853943e-07\n",
      "5.68723970156e-08 1.90432580315e-08\n",
      "Detection rate of Sensitive features (on Test Data): 0.395\n",
      "Accuracy of Utility (on Test Data): 0.1135\n",
      "Epoch= 5 \n",
      "\n",
      "5.57518267835e-08\n",
      "3.37658043877e-08 1.17334887115e-08\n",
      "Detection rate of Sensitive features (on Test Data): 0.3967\n",
      "Accuracy of Utility (on Test Data): 0.1135\n",
      "Epoch= 6 \n",
      "\n",
      "3.30325962171e-08\n",
      "2.11944544307e-08 7.64350178625e-09\n",
      "Detection rate of Sensitive features (on Test Data): 0.3974\n",
      "Accuracy of Utility (on Test Data): 0.1134\n",
      "Epoch= 7 \n",
      "\n",
      "2.07306898532e-08\n",
      "1.38196603736e-08 5.13359447558e-09\n",
      "Detection rate of Sensitive features (on Test Data): 0.3972\n",
      "Accuracy of Utility (on Test Data): 0.1135\n",
      "Epoch= 8 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-448-d658c3d26a0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mbatch_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXTrainPrime\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYTrainPrime\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEncoderOptimizer1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;31m#_, c4 = sess.run([EncoderOptimizer2, LookSimilarCost], feed_dict={x: batch_xs, y: batch_ys})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mavg_cost3\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc3\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\userlocal\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#4B\n",
    "#XTrial = XTrainPrime[:100]\n",
    "#YTrial = YTrainPrime[:100]\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    avg_cost3 = 0.\n",
    "    avg_cost4 = 0.\n",
    "    total_batch = int(int(XTrainPrime.shape[0])/batch_size)\n",
    "    print (\"Epoch=\",epoch,'\\n')\n",
    "    #print (total_batch)\n",
    "    for i in range(total_batch):\n",
    "        #print ('i=',i)\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c3 = sess.run([EncoderOptimizer1, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        #_, c4 = sess.run([EncoderOptimizer2, LookSimilarCost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "    avg_cost3 += c3 / total_batch\n",
    "    #avg_cost4 += c4 / total_batch\n",
    "    print (avg_cost3) \n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        #print ('i=',i)\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c2 = sess.run([ClassifierOptimizer1, CostV], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        _, c1 = sess.run([ClassifierOptimizer2, CostU], feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "    avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "\n",
    "    print (avg_cost1,avg_cost2)\n",
    "    #print (avg_cost3)\n",
    "    print (\"Detection rate of Sensitive features (on Test Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "    print (\"Accuracy of Utility (on Test Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "\n",
    "    #if (epoch+1) % display_step == 0:\n",
    "\n",
    "#        print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "print (\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4C\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "#print ((tf.argmax(y[:,10:], 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "#a=(tf.argmax(predU, 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime})\n",
    "#print (XTestPrime.shape)\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "print (\"Detection rate of Sensitive features (on Test Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "print (\"Accuracy of Utility (on Test Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=s[0]\n",
    "temp1 = XTrainPrime[n].reshape((1,784))\n",
    "temp2 = temp1.reshape((28,28))\n",
    "X=EncImages.eval(session=sess,feed_dict={x:temp1})\n",
    "TempImage = X.reshape((28,28))\n",
    "plt.imshow(temp2, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()\n",
    "distance = np.sqrt(np.sum((X-temp1)**2))\n",
    "print (\"Difference between encoded and original image is\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3A\n",
    "\n",
    "alpha = (1/16)\n",
    "SensitiveLabels = YTrial[:,10:12]\n",
    "    \n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 12]) # 0-9 digits recognition => 1 class\n",
    "\n",
    "\n",
    "'''-----------------------------------------Encoder Training----------------------------------------------------'''\n",
    "W1 = tf.Variable(tf.random_normal([784, 500], mean=0, stddev=1))\n",
    "b1 = tf.Variable(tf.random_normal([500], mean=0, stddev = 1))\n",
    "W2 = tf.Variable(tf.random_normal([500, 1000],mean=0, stddev=1))\n",
    "b2 = tf.Variable(tf.random_normal([1000],mean=0, stddev=1))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([1000, 784], mean=0, stddev=1))\n",
    "b3 = tf.Variable(tf.random_normal([784], mean=0, stddev = 1))\n",
    "\n",
    "\n",
    "Hidden1 = tf.nn.relu(tf.matmul(x, W1) + b1);\n",
    "Hidden3 = tf.nn.relu(tf.matmul(Hidden1, W2) + b2);\n",
    "EncImagesTemp = tf.nn.relu(tf.matmul(Hidden3, W3) + b3);\n",
    "\n",
    "c = tf.reduce_max(EncImagesTemp)\n",
    "d = tf.reduce_min(EncImagesTemp)\n",
    "EncImages = tf.divide(EncImagesTemp,(c-d))\n",
    "EncoderParameters = [W1,b1,W2,b2,W3,b3]\n",
    "    \n",
    "'''---------------------------------------Classifier Training----------------------------------------'''\n",
    "W4 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b4 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "\n",
    "\n",
    "W5 = tf.Variable(tf.random_normal([300, 10],mean=0, stddev=1))\n",
    "b5 = tf.Variable(tf.random_normal([10],mean=0, stddev=1))\n",
    "\n",
    "W6 = tf.Variable(tf.random_normal([300, 2],mean=0, stddev=1))\n",
    "b6 = tf.Variable(tf.random_normal([2],mean=0, stddev=1))\n",
    "\n",
    "Hidden2 = tf.nn.relu(tf.matmul(EncImages, W4) + b4);\n",
    "OutputLayer1 = tf.matmul(Hidden2, W5) + b5;\n",
    "OutputLayer2 = tf.matmul(Hidden2, W6) + b6;\n",
    "ClassifierParameters1 = [W4,b4,W5,b5]\n",
    "ClassifierParameters2 = [W3,b3,W6,b6]\n",
    "#print (ClassifierParameters)\n",
    "    \n",
    "  # Optimization\n",
    "learning_rateU = 0.001\n",
    "learning_rateV = 0.001\n",
    "learning_rateE1 = 0.001\n",
    "learning_rateE2 = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "lambda1 = 1\n",
    "lambda2 = 1\n",
    "print ('Entering Optimization')\n",
    "    \n",
    "predV = tf.nn.softmax(OutputLayer1)\n",
    "predU = tf.nn.softmax(OutputLayer2)\n",
    "\n",
    "CostV = tf.reduce_mean(-tf.reduce_sum(y[:,:10]*tf.log(tf.clip_by_value(predV,1e-5,1.0)), reduction_indices=1))\n",
    "CostU = tf.reduce_mean(-tf.reduce_sum(y[:,10:]*tf.log(tf.clip_by_value(predU,1e-5,1.0)), reduction_indices=1))\n",
    "\n",
    "var = tf.reduce_mean(tf.reduce_mean(EncImages**2,reduction_indices=1))\n",
    "#cost = CostU - (alpha*CostV)\n",
    "cost = CostU - (alpha*CostV)\n",
    "#LookSimilarCost = tf.sqrt(tf.reduce_sum((x-EncImages)**2))\n",
    "\n",
    "ClassifierOptimizer1 = tf.train.AdamOptimizer(learning_rate=learning_rateU).minimize(CostU,var_list=ClassifierParameters2)\n",
    "ClassifierOptimizer2 = tf.train.AdamOptimizer(learning_rate=learning_rateV).minimize(CostV,var_list=ClassifierParameters1)\n",
    "EncoderOptimizer1 = tf.train.AdamOptimizer(learning_rate=learning_rateE1).minimize(-cost,var_list=EncoderParameters)\n",
    "#EncoderOptimizer2 = tf.train.AdamOptimizer(learning_rate=learning_rateE2).minimize(LookSimilarCost,var_list=EncoderParameters)\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "#print ((tf.argmax(y[:,10:], 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "#a=(tf.argmax(predU, 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime})\n",
    "#print (XTestPrime.shape)\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3B\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    avg_cost3 = 0.\n",
    "    avg_cost4 = 0.\n",
    "    total_batch = int(int(XTrainPrime.shape[0])/batch_size)\n",
    "    print (\"Epoch=\",epoch,'\\n')\n",
    "    for i in range(total_batch):\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c3 = sess.run([EncoderOptimizer1, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        #_, c4 = sess.run([EncoderOptimizer2, LookSimilarCost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "    avg_cost3 += c3 / total_batch\n",
    "    avg_cost4 += c4 / total_batch\n",
    "    print (avg_cost3) \n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        #print ('i=',i)\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c2 = sess.run([ClassifierOptimizer1, CostV], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        _, c1 = sess.run([ClassifierOptimizer2, CostU], feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "    avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "\n",
    "    print (avg_cost1,avg_cost2)\n",
    "    print (\"Detection rate of Sensitive features (on Test Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "    print (\"Accuracy of Utility (on Test Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "\n",
    "print (\"Optimization Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3C\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "#print ((tf.argmax(y[:,10:], 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "#a=(tf.argmax(predU, 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime})\n",
    "#print (XTestPrime.shape)\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "print (\"Detection rate of Sensitive features (on Test Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "print (\"Accuracy of Utility (on Test Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=s[0]\n",
    "temp1 = XTrainPrime[n].reshape((1,784))\n",
    "temp2 = temp1.reshape((28,28))\n",
    "X=EncImages.eval(session=sess,feed_dict={x:temp1})\n",
    "TempImage = X.reshape((28,28))\n",
    "plt.imshow(temp2, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()\n",
    "distance = np.sqrt(np.sum((X-temp1)**2))\n",
    "print (\"Difference between encoded and original image is\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (EncImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d269c7828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "XTrain = mnist.train.images\n",
    "YTrain = mnist.train.labels\n",
    "XTest = mnist.test.images\n",
    "YTest = mnist.test.labels\n",
    "\n",
    "X=XTrain[1]\n",
    "TempImage = X.reshape((28,28))\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "No. of images changed are 55000\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "     /\n",
    "    /\n",
    "\\  /\n",
    " \\/\n",
    "'''\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "XTrain = mnist.train.images\n",
    "YTrain = mnist.train.labels\n",
    "XTest = mnist.test.images\n",
    "YTest = mnist.test.labels\n",
    "# Another kind of dataset\n",
    "def MoreTransformMNIST (OrigX,OrigY):\n",
    "\n",
    "\n",
    "    samples = int(OrigX.shape[0])\n",
    "    SelectedImages = np.random.choice(samples,int(OrigX.shape[0]),replace=False) #Choose random images to insert sensitive information\n",
    "\n",
    "    print ('No. of images changed are', SelectedImages.shape[0])\n",
    "    s = SelectedImages.shape[0]\n",
    "    SelectedImages1 = SelectedImages[:int(s/2)]\n",
    "    SelectedImages2 = SelectedImages[int(s/2):]\n",
    "    \n",
    "    SubX1 = OrigX[SelectedImages1]\n",
    "    SubX2 = OrigX[SelectedImages2]\n",
    "    for o in range(784):\n",
    "        if o % 13 == 0:\n",
    "            SubX1[:,o] = 1\n",
    "        if (o%10) == 0:               \n",
    "            SubX2[:,o] = 1\n",
    "        #elif o>=364 and o<378:\n",
    "        #    SubX1[:,o] = 1\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    SenYCol = np.zeros((OrigY.shape[0],2))\n",
    "    NewY = np.concatenate((OrigY,SenYCol),axis=1)\n",
    "    NewX = OrigX\n",
    "# If plus sign then Y = 01 else Y = 10\n",
    "    for num,i in enumerate(SelectedImages1):\n",
    "        NewX[i]=SubX1[num]\n",
    "        NewY[i][11]=1\n",
    "    for num,i in enumerate(SelectedImages2):\n",
    "        NewX[i]=SubX2[num]\n",
    "        NewY[i][10]=1\n",
    "    return (SelectedImages1, SelectedImages2, NewX, NewY)\n",
    "\n",
    "s1,s2,XTrainPrime, YTrainPrime = MoreTransformMNIST(XTrain,YTrain)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "XTrain = mnist.train.images\n",
    "YTrain = mnist.train.labels\n",
    "XTest = mnist.test.images\n",
    "YTest = mnist.test.labels\n",
    "# _,XTestPrime, YTestPrime = MoreTransformMNIST(30,XTest,YTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4Ii/EBQ/w+Qsima06z3vwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d99a46908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADhFJREFUeJzt3V2MVPUZx/HfU9Eb9EJZuhLFxRqDUS/QrKYXSDRWFGMC\n3BhfYmiqrDGaFO1F8SXWBEXTVCvcoGskYuNbA2wkBquWNECThvBmfdkFtQYFgiyIiRovrO7Tizk0\nq+75n2HmzJxZnu8n2ezMeebMPB73x5kz/znnb+4uAPH8rOoGAFSD8ANBEX4gKMIPBEX4gaAIPxAU\n4QeCIvxAUIQfCGpCO1/MzPg6IdBi7m71PK6pPb+ZXWNmu83sIzNb3MxzAWgva/S7/WZ2gqQPJF0l\naZ+krZJudPfBxDrs+YEWa8ee/1JJH7n7x+7+raSXJc1t4vkAtFEz4T9D0t5R9/dly37AzPrMbJuZ\nbWvitQCUrOUf+Ll7v6R+ibf9QCdpZs+/X9LUUffPzJYBGAeaCf9WSeea2dlmdpKkGyStK6ctAK3W\n8Nt+d//OzO6S9IakEyStdPf3S+sMQEs1PNTX0ItxzA+0XFu+5ANg/CL8QFCEHwiK8ANBEX4gKMIP\nBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjC\nDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqIan6JYkM9sj6StJ30v6zt17y2gK7dPT05Os33bb\nbcn6/fffn6ynZoE2S08mOzQ0lKw/8MADyfrAwECyHl1T4c9c4e6HS3geAG3E234gqGbD75LeNLPt\nZtZXRkMA2qPZt/0z3X2/mf1c0ltmtsvdN41+QPaPAv8wAB2mqT2/u+/Pfg9LGpB06RiP6Xf3Xj4M\nBDpLw+E3s4lmdsrR25JmS3qvrMYAtFYzb/u7JQ1kwzUTJL3o7n8rpSsALWepcdjSX8ysfS8WyOTJ\nk3Nr9957b3Ldm2++OVmfNGlSsl40Vt/MOH/R3+bevXuT9UsuuSS3dvjw8Ts67e7pDZthqA8IivAD\nQRF+ICjCDwRF+IGgCD8QFEN940DRabNLlizJrRX9/231cNuhQ4eS9ZSurq5kfdq0acn64OBgbu2C\nCy5opKVxgaE+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4/zjwNatW5P1iy++OLfW7Dh/aqxckq64\n4opkvZlTZ2fOnJmsb9y4MVlP/bdPmFDGhas7E+P8AJIIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvk7\nwHnnnZesF43zf/7557m1ovPpi8bh77777mR90aJFyfrSpUtza59++mly3SJFf7sjIyO5tTvuuCO5\nbn9/f0M9dQLG+QEkEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIXj/Ga2UtJ1kobd/cJs2WmSXpE0TdIe\nSde7+xeFL8Y4f0OKvgeQGqtvdirqvr6+ZH3FihXJemqa7B07diTXnT9/frK+evXqZD31t3366acn\n1x3PU3iXOc7/nKRrfrRssaQN7n6upA3ZfQDjSGH43X2TpCM/WjxX0qrs9ipJ80ruC0CLNXrM3+3u\nB7Lbn0nqLqkfAG3S9IXM3N1Tx/Jm1icpfeAIoO0a3fMfNLMpkpT9Hs57oLv3u3uvu/c2+FoAWqDR\n8K+TtCC7vUDSq+W0A6BdCsNvZi9J+pek6Wa2z8xulfSYpKvM7ENJv8ruAxhHCo/53f3GnNKVJfeC\nHLt27arstYuuB7B79+5kPXWtgaJrBSxenB5BLppzoJXffzge8A0/ICjCDwRF+IGgCD8QFOEHgiL8\nQFDH7zzFgcyaNSu3VnQ6cNFQ3tDQULI+ffr0ZH3Lli25tcmTJyfXLTrdvKj3OXPmJOvRsecHgiL8\nQFCEHwiK8ANBEX4gKMIPBEX4gaAY5z8O3HTTTbm1hQsXJtctOi22jku7J+upsfxmTsmVpOXLlyfr\nRZcGj449PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTj/ca5onL7K9Tdv3pxc95577knWGcdvDnt+\nICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiqcJzfzFZKuk7SsLtfmC17SNJCSUcvnH6fu69vVZNIe/HF\nF3NrPT09yXW7urqS9aLr/k+cODFZT3nwwQeTdcbxW6uePf9zkq4ZY/mf3X1G9kPwgXGmMPzuvknS\nkTb0AqCNmjnmv8vM3jGzlWZ2amkdAWiLRsO/QtI5kmZIOiDp8bwHmlmfmW0zs20NvhaAFmgo/O5+\n0N2/d/cRSc9IujTx2H5373X33kabBFC+hsJvZlNG3Z0v6b1y2gHQLvUM9b0k6XJJXWa2T9IfJF1u\nZjMkuaQ9km5vYY8AWsCaPV/7mF7MrH0vhlIUjfM//PDDyfq8efNyazt37kyuO2fOnGS96Lr+Ubl7\nekKEDN/wA4Ii/EBQhB8IivADQRF+ICjCDwTFUF+dUlNNHzp0KLcW3euvv55bu/rqq5PrFl26+8kn\nn2yop+MdQ30Akgg/EBThB4Ii/EBQhB8IivADQRF+ICim6M7MmjUrWX/88dwrlWnXrl3JdW+55ZaG\nejoePPLII7m12bNnJ9edPn162e1gFPb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUmHH+1Pn4kvTU\nU08l68PDw7m1yOP4RVN0P/3007k1s7pOO0eLsOcHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAKx/nN\nbKqk5yV1S3JJ/e6+zMxOk/SKpGmS9ki63t2/aF2rzZk/f36yXnTu+MaNG8tsZ9womqJ7zZo1yXpq\nuxbNGVF0nQQ0p549/3eSfufu50v6paQ7zex8SYslbXD3cyVtyO4DGCcKw+/uB9x9R3b7K0lDks6Q\nNFfSquxhqyTNa1WTAMp3TMf8ZjZN0kWStkjqdvcDWekz1Q4LAIwTdX+338xOlrRG0iJ3/3L097Ld\n3fPm4TOzPkl9zTYKoFx17fnN7ETVgv+Cu6/NFh80sylZfYqkMc98cfd+d+91994yGgZQjsLwW20X\n/6ykIXd/YlRpnaQF2e0Fkl4tvz0ArVI4RbeZzZS0WdK7kkayxfepdtz/V0lnSfpEtaG+IwXPVdkU\n3UVDVkNDQ8n64OBgbu3RRx9t6rm3b9+erBfp6enJrV122WXJdYuGQOfNS3+OW3Raburva9myZcl1\ni6boxtjqnaK78Jjf3f8pKe/JrjyWpgB0Dr7hBwRF+IGgCD8QFOEHgiL8QFCEHwiqcJy/1BercJy/\nyOrVq5P11Hh3M2PdkrRz585kvchZZ52VW5s0aVJy3WZ7L1o/NUX38uXLk+sePnw4WcfY6h3nZ88P\nBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzp8pmsJ7/fr1ubXe3vRFikZGRpL1Vo61F637zTffJOtF\nl89eunRpsj4wMJCso3yM8wNIIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnr1NXV1dubcmSJU09d19f\nejaztWvXJuvNnPdedO18pskefxjnB5BE+IGgCD8QFOEHgiL8QFCEHwiK8ANBFY7zm9lUSc9L6pbk\nkvrdfZmZPSRpoaRD2UPvc/f8k941vsf5gfGi3nH+esI/RdIUd99hZqdI2i5pnqTrJX3t7n+qtynC\nD7ReveGfUMcTHZB0ILv9lZkNSTqjufYAVO2YjvnNbJqkiyRtyRbdZWbvmNlKMzs1Z50+M9tmZtua\n6hRAqer+br+ZnSxpo6RH3H2tmXVLOqza5wBLVDs0+E3Bc/C2H2ix0o75JcnMTpT0mqQ33P2JMerT\nJL3m7hcWPA/hB1qstBN7rHZp2GclDY0OfvZB4FHzJb13rE0CqE49n/bPlLRZ0ruSjl6D+j5JN0qa\nodrb/j2Sbs8+HEw9F3t+oMVKfdtfFsIPtB7n8wNIIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTh\nB4Ii/EBQhB8IivADQRF+ICjCDwRVeAHPkh2W9Mmo+13Zsk7Uqb11al8SvTWqzN566n1gW8/n/8mL\nm21z997KGkjo1N46tS+J3hpVVW+87QeCIvxAUFWHv7/i10/p1N46tS+J3hpVSW+VHvMDqE7Ve34A\nFakk/GZ2jZntNrOPzGxxFT3kMbM9Zvaumb1d9RRj2TRow2b23qhlp5nZW2b2YfZ7zGnSKurtITPb\nn227t83s2op6m2pm/zCzQTN738x+my2vdNsl+qpku7X9bb+ZnSDpA0lXSdonaaukG919sK2N5DCz\nPZJ63b3yMWEzmyXpa0nPH50Nycz+KOmIuz+W/cN5qrv/vkN6e0jHOHNzi3rLm1n616pw25U543UZ\nqtjzXyrpI3f/2N2/lfSypLkV9NHx3H2TpCM/WjxX0qrs9irV/njaLqe3juDuB9x9R3b7K0lHZ5au\ndNsl+qpEFeE/Q9LeUff3qbOm/HZJb5rZdjPrq7qZMXSPmhnpM0ndVTYzhsKZm9vpRzNLd8y2a2TG\n67Lxgd9PzXT3iyXNkXRn9va2I3ntmK2ThmtWSDpHtWncDkh6vMpmspml10ha5O5fjq5Vue3G6KuS\n7VZF+PdLmjrq/pnZso7g7vuz38OSBlQ7TOkkB49Okpr9Hq64n/9z94Pu/r27j0h6RhVuu2xm6TWS\nXnD3tdniyrfdWH1Vtd2qCP9WSeea2dlmdpKkGyStq6CPnzCzidkHMTKziZJmq/NmH14naUF2e4Gk\nVyvs5Qc6ZebmvJmlVfG267gZr9297T+SrlXtE///SLq/ih5y+vqFpH9nP+9X3Zukl1R7G/hf1T4b\nuVXSJEkbJH0o6e+STuug3v6i2mzO76gWtCkV9TZTtbf070h6O/u5tuptl+irku3GN/yAoPjADwiK\n8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUP8DUODl2qszuRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d99a2f400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d99b5e1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOEHkvo/XKE+/IkWWDoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26d99a24d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=s2[0]\n",
    "X=XTrainPrime[n]\n",
    "TempImage = X.reshape((28,28))\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()\n",
    "X1=XTrain[n]\n",
    "TempImage1 = X1.reshape((28,28))\n",
    "plt.imshow(TempImage1, cmap='gray')\n",
    "plt.show()\n",
    "m=s1[0]\n",
    "X=XTrainPrime[m]\n",
    "TempImage = X.reshape((28,28))\n",
    "plt.imshow(TempImage, cmap='gray')\n",
    "plt.show()\n",
    "X1=XTrain[m]\n",
    "TempImage1 = X1.reshape((28,28))\n",
    "plt.imshow(TempImage1, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering Optimization\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The architecture is same but there are some added constraints. Now all the encoded images have to have zero mean \n",
    "and unit variance. This is done to not saturate the encoder to a constant solution and will try to look similar \n",
    "to the original digit without any attribute.\n",
    "But doing the training on a new dataset\n",
    "'''\n",
    "\n",
    "alpha = (1)\n",
    "\n",
    "    \n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 12]) # 0-9 digits recognition => 1 class\n",
    "\n",
    "\n",
    "'''-----------------------------------------Encoder Training----------------------------------------------------'''\n",
    "W1 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b1 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W2 = tf.Variable(tf.random_normal([300, 784],mean=0, stddev=1))\n",
    "b2 = tf.Variable(tf.random_normal([784],mean=0, stddev=1))\n",
    "\n",
    "Hidden1 = tf.nn.relu(tf.matmul(x, W1) + b1);\n",
    "TempLayer = tf.matmul(Hidden1, W2) + b2\n",
    "MeanTempLayer  = tf.reduce_mean(TempLayer)\n",
    "m = tf.reduce_mean(TempLayer,axis=1)\n",
    "m = tf.convert_to_tensor([m]*784)\n",
    "m = tf.reshape(m,(-1,784))\n",
    "VarTempLayer  = tf.reduce_mean((TempLayer-m)**2)\n",
    "EncImagesTemp = tf.nn.tanh(tf.matmul(Hidden1, W2) + b2);\n",
    "#These are the encodings of the images\n",
    "\n",
    "c = tf.reduce_max(EncImagesTemp)\n",
    "d = tf.reduce_min(EncImagesTemp)\n",
    "#The Encodings need to be scaled so that the final values are between 0 and 1 (like original MNIST)\n",
    "EncImages = tf.divide((EncImagesTemp-d),(c-d))\n",
    "L2Norm = tf.sqrt(tf.reduce_sum((EncImages - x)**2))\n",
    "\n",
    "EncoderParameters = [W1,b1,W2,b2]\n",
    "    \n",
    "'''---------------------------------------Classifier Training----------------------------------------'''\n",
    "#W3,b3,W4,b4 helps in classifying utility\n",
    "W3 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b3 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W4 = tf.Variable(tf.random_normal([300, 10]))\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "Hidden2 = tf.nn.relu(tf.matmul(EncImages, W3) + b3);\n",
    "OutputLayer1 = tf.matmul(Hidden2, W4) + b4;\n",
    "ClassifierParameters1 = [W3,b3,W4,b4]\n",
    "\n",
    "#W5,b5,W6,b6 helps in classifying sensitive features\n",
    "W5 = tf.Variable(tf.random_normal([784, 300], mean=0, stddev=1))\n",
    "b5 = tf.Variable(tf.random_normal([300], mean=0, stddev = 1))\n",
    "W6 = tf.Variable(tf.random_normal([300, 2]))\n",
    "b6 = tf.Variable(tf.random_normal([2]))\n",
    "\n",
    "Hidden3 = tf.nn.relu(tf.matmul(EncImages, W5) + b5);\n",
    "OutputLayer2 = tf.matmul(Hidden3, W6) + b6;\n",
    "ClassifierParameters2 = [W5,b5,W6,b6]    \n",
    "  # Optimization\n",
    "learning_rateU = 0.0001\n",
    "learning_rateV = 0.0003\n",
    "learning_rateE = 0.0005\n",
    "training_epochs = 30\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "lambda1 = 0.05\n",
    "lambda2 = 0.05\n",
    "lambda3 = 0.05\n",
    "print ('Entering Optimization')\n",
    "    \n",
    "predV = tf.nn.softmax(OutputLayer1)\n",
    "predU = tf.nn.softmax(OutputLayer2)\n",
    "\n",
    "CostV = tf.reduce_mean(-tf.reduce_sum(y[:,:10]*tf.log(tf.clip_by_value(predV,1e-10,1.0)), reduction_indices=1))\n",
    "CostU = tf.reduce_mean(-tf.reduce_sum(y[:,10:]*tf.log(tf.clip_by_value(predU,1e-10,1.0)), reduction_indices=1))\n",
    "\n",
    "#Batch normalization will happen across a batch\n",
    "\n",
    "#cost = CostU - (alpha*CostV) - (lambda1*MeanTempLayer) - lambda2*(VarTempLayer-1) - lambda3*(L2Norm)\n",
    "cost = CostU - (alpha*CostV)- lambda3*(L2Norm)\n",
    "#print (MeanTempLayer,VarTempLayer,L2Norm)\n",
    "ClassifierOptimizer1 = tf.train.AdamOptimizer(learning_rate=learning_rateV).minimize(CostV,var_list=ClassifierParameters1)\n",
    "ClassifierOptimizer2 = tf.train.AdamOptimizer(learning_rate=learning_rateU).minimize(CostU,var_list=ClassifierParameters2)\n",
    "EncoderOptimizer = tf.train.AdamOptimizer(learning_rate=learning_rateE).minimize(-cost,var_list=EncoderParameters)\n",
    "\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "#print (\"Detection rate of Sensitive features (on Test Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "#print (\"Accuracy of Utility (on Test Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26dd06ea828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p=EncImages.eval(session=sess,feed_dict={x:XTrainPrime,y:YTrainPrime})\n",
    "q=p[0].reshape((28,28))\n",
    "_, c3 = sess.run([EncoderOptimizer, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "plt.imshow(q, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "Epoch= 0\n",
      "Encoder cost -0.0352933086048\n",
      "Utility cost: 0.0209334911 Private attribute cost: 0.0221885473078\n",
      "Epoch Accuracy 0.477655\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "550\n",
      "Epoch= 1\n",
      "Encoder cost -0.0346729555997\n",
      "Utility cost: 0.0209622521834 Private attribute cost: 0.0221885473078\n",
      "Epoch Accuracy 0.477036\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "550\n",
      "Epoch= 2\n",
      "Encoder cost -0.0346790140325\n",
      "Utility cost: 0.0213512420654 Private attribute cost: 0.0221885473078\n",
      "Epoch Accuracy 0.474945\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "550\n",
      "Epoch= 3\n",
      "Encoder cost -0.0349158547141\n",
      "Utility cost: 0.0217699102922 Private attribute cost: 0.0221885473078\n",
      "Epoch Accuracy 0.4782\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "550\n",
      "Epoch= 4\n",
      "Encoder cost -0.0343915627219\n",
      "Utility cost: 0.0213512420654 Private attribute cost: 0.0221885473078\n",
      "Epoch Accuracy 0.477055\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "550\n",
      "Epoch= 5\n",
      "Encoder cost -0.0337451761419\n",
      "Utility cost: 0.0209326431968 Private attribute cost: 0.0221885473078\n",
      "Epoch Accuracy 0.479145\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "550\n",
      "Epoch= 6\n",
      "Encoder cost -0.0338572103327\n",
      "Utility cost: 0.0207885811546 Private attribute cost: 0.0221885473078\n",
      "Epoch Accuracy 0.480764\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "550\n",
      "Epoch= 7\n",
      "Encoder cost -0.0343328302557\n",
      "Utility cost: 0.0213621520996 Private attribute cost: 0.0221885473078\n",
      "Epoch Accuracy 0.482545\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "550\n",
      "Epoch= 8\n",
      "Encoder cost -0.035170731978\n",
      "Utility cost: 0.0220067908547 Private attribute cost: 0.0221885473078\n",
      "Epoch Accuracy 0.479618\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "550\n",
      "Epoch= 9\n",
      "Encoder cost -0.0337828063965\n",
      "Utility cost: 0.0213512420654 Private attribute cost: 0.0221885473078\n",
      "Epoch Accuracy 0.481236\n",
      "Accuracy with which sensitive features are detected 0.5\n",
      "\n",
      "\n",
      "Optimization Finished!\n",
      "Detection rate of Sensitive features (on Test Data): 0.5\n",
      "Accuracy of Utility (on Training Data): 0.481236\n"
     ]
    }
   ],
   "source": [
    "#1B\n",
    "EA = []\n",
    "PA = []\n",
    "alpha = 2\n",
    "lambda3 = 0.05\n",
    "training_epochs = 10\n",
    "XTrial = XTrainPrime\n",
    "YTrial = YTrainPrime\n",
    "batch_size = 100\n",
    "learning_rateU = 0.0001\n",
    "learning_rateV = 0.0006\n",
    "learning_rateE = 0.0003\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost1 = 0.\n",
    "    avg_cost2 = 0.\n",
    "    avg_cost3 = 0.\n",
    "    total_batch = int(int(XTrainPrime.shape[0])/batch_size)\n",
    "    print (total_batch)\n",
    "    print (\"Epoch=\",epoch)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        #print ('esha')\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c3 = sess.run([EncoderOptimizer, cost], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        #print (c3)\n",
    "    avg_cost3 += c3 / total_batch\n",
    "    print ('Encoder cost', avg_cost3) \n",
    "    \n",
    "    for i in range(total_batch):\n",
    "\n",
    "        batch_xs = XTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        batch_ys = YTrainPrime[(i*batch_size):((i+1)*batch_size)]\n",
    "        _, c1 = sess.run([ClassifierOptimizer1, CostV], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        _, c2 = sess.run([ClassifierOptimizer2, CostU], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        #print (c1)\n",
    "        #print (c2)\n",
    "    avg_cost1 += c1 / total_batch\n",
    "    avg_cost2 += c2 / total_batch\n",
    "    print ('Utility cost:',avg_cost1,'Private attribute cost:',avg_cost2)\n",
    "    EpochAccuracy = AccuracyV.eval(session=sess,feed_dict={x: XTrial, y: YTrial})\n",
    "    SenAcc = AccuracyU.eval(session=sess,feed_dict={x: XTrial, y: YTrial})\n",
    "    print ('Epoch Accuracy',EpochAccuracy)\n",
    "    print ('Accuracy with which sensitive features are detected', SenAcc)\n",
    "    EA.append(AccuracyV.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "    PA.append(AccuracyU.eval(session=sess,feed_dict={x: XTrainPrime, y: YTrainPrime}))\n",
    "#     if (EpochAccuracy > 0.6):\n",
    "#         #print ('yippie')\n",
    "#         learning_rateU = 0.001\n",
    "#         learning_rateV = 0.0005\n",
    "#         learning_rateE = 0.001\n",
    "#     if (EpochAccuracy > 0.8):\n",
    "#         #print ('yippie')\n",
    "#         learning_rateU = 0.0001\n",
    "#         learning_rateV = 0.0001\n",
    "#         learning_rateE = 0.0005\n",
    "#         alpha = 1.5\n",
    "    print ('\\n')\n",
    "print (\"Optimization Finished!\")\n",
    "correct_predictionV = tf.equal(tf.argmax(predV, 1), tf.argmax(y[:,:10], 1))\n",
    "correct_predictionU = tf.equal(tf.argmax(predU, 1), tf.argmax(y[:,10:], 1))\n",
    "\n",
    "#print ((tf.argmax(y[:,10:], 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime}))\n",
    "#a=(tf.argmax(predU, 1)).eval(session=sess,feed_dict={x: XTestPrime, y: YTestPrime})\n",
    "#print (XTestPrime.shape)\n",
    "\n",
    "AccuracyU = tf.reduce_mean(tf.cast(correct_predictionU, tf.float32))\n",
    "AccuracyV = tf.reduce_mean(tf.cast(correct_predictionV, tf.float32))\n",
    "print (\"Detection rate of Sensitive features (on Test Data):\", AccuracyU.eval(session=sess,feed_dict={x: XTrial, y: YTrial}))\n",
    "print (\"Accuracy of Utility (on Training Data):\", AccuracyV.eval(session=sess,feed_dict={x: XTrial, y: YTrial}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#total_batch = int(int(XTrial.shape[0])/batch_size)\n",
    "\n",
    "print (int(XTrainPrime.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
